{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/israel/repos/Mask_RCNN/samples')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testfile import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/israel/repos/detectron2/demo/')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictor import VisualizationDemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisualizationDemo(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, vis_output = model.run_on_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['instances'].pred_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "im = cv2.imread(\"/home/israel/repos/labelme/examples/test/2011_000025.jpg\")\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/home/israel/repos/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # set threshold for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
    "cfg.MODEL.DEVICE='cpu'\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = outputs['instances'].pred_masks.to('cpu').numpy()\n",
    "labels = outputs['instances'].pred_classes.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "for i, label in enumerate(labels):\n",
    "    Mask(mask[0]).polygons()\n",
    "    polygons = Mask(mask[i]).polygons()\n",
    "    points = polygons.points[0][::5]\n",
    "    points = list(map(tuple, points.astype('float')))\n",
    "    instance = {'label': class_names[label],\n",
    "                'points': points,\n",
    "                'group_id': None,\n",
    "                'shape_type': 'polygon',\n",
    "                'flags': {}}\n",
    "    shapes.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'bus',\n",
       "  'points': [(4.0, 99.0),\n",
       "   (0.0, 108.0),\n",
       "   (0.0, 243.0),\n",
       "   (3.0, 267.0),\n",
       "   (5.0, 281.0),\n",
       "   (10.0, 279.0),\n",
       "   (18.0, 276.0),\n",
       "   (34.0, 280.0),\n",
       "   (50.0, 281.0),\n",
       "   (63.0, 280.0),\n",
       "   (69.0, 277.0),\n",
       "   (76.0, 270.0),\n",
       "   (79.0, 263.0),\n",
       "   (82.0, 256.0),\n",
       "   (84.0, 251.0),\n",
       "   (87.0, 245.0),\n",
       "   (89.0, 238.0),\n",
       "   (92.0, 230.0),\n",
       "   (94.0, 224.0),\n",
       "   (98.0, 211.0),\n",
       "   (96.0, 172.0),\n",
       "   (93.0, 162.0),\n",
       "   (91.0, 148.0),\n",
       "   (87.0, 142.0),\n",
       "   (85.0, 134.0),\n",
       "   (82.0, 118.0),\n",
       "   (74.0, 112.0),\n",
       "   (63.0, 109.0),\n",
       "   (52.0, 107.0),\n",
       "   (33.0, 104.0),\n",
       "   (23.0, 102.0)],\n",
       "  'group_id': None,\n",
       "  'shape_type': 'polygon',\n",
       "  'flags': {}},\n",
       " {'label': 'bus',\n",
       "  'points': [(168.0, 27.0),\n",
       "   (156.0, 30.0),\n",
       "   (151.0, 32.0),\n",
       "   (144.0, 37.0),\n",
       "   (138.0, 39.0),\n",
       "   (125.0, 50.0),\n",
       "   (120.0, 54.0),\n",
       "   (116.0, 62.0),\n",
       "   (114.0, 67.0),\n",
       "   (110.0, 74.0),\n",
       "   (108.0, 83.0),\n",
       "   (105.0, 91.0),\n",
       "   (101.0, 98.0),\n",
       "   (97.0, 105.0),\n",
       "   (97.0, 142.0),\n",
       "   (100.0, 161.0),\n",
       "   (100.0, 198.0),\n",
       "   (99.0, 221.0),\n",
       "   (97.0, 230.0),\n",
       "   (96.0, 323.0),\n",
       "   (98.0, 338.0),\n",
       "   (103.0, 345.0),\n",
       "   (108.0, 351.0),\n",
       "   (122.0, 355.0),\n",
       "   (149.0, 353.0),\n",
       "   (159.0, 350.0),\n",
       "   (166.0, 348.0),\n",
       "   (173.0, 345.0),\n",
       "   (188.0, 343.0),\n",
       "   (243.0, 344.0),\n",
       "   (303.0, 342.0),\n",
       "   (326.0, 339.0),\n",
       "   (347.0, 341.0),\n",
       "   (364.0, 344.0),\n",
       "   (396.0, 344.0),\n",
       "   (406.0, 339.0),\n",
       "   (412.0, 334.0),\n",
       "   (419.0, 325.0),\n",
       "   (421.0, 316.0),\n",
       "   (422.0, 300.0),\n",
       "   (424.0, 269.0),\n",
       "   (425.0, 252.0),\n",
       "   (423.0, 244.0),\n",
       "   (420.0, 238.0),\n",
       "   (418.0, 227.0),\n",
       "   (415.0, 219.0),\n",
       "   (413.0, 214.0),\n",
       "   (410.0, 209.0),\n",
       "   (412.0, 150.0),\n",
       "   (415.0, 144.0),\n",
       "   (417.0, 130.0),\n",
       "   (416.0, 106.0),\n",
       "   (413.0, 98.0),\n",
       "   (408.0, 90.0),\n",
       "   (406.0, 83.0),\n",
       "   (402.0, 76.0),\n",
       "   (397.0, 67.0),\n",
       "   (394.0, 57.0),\n",
       "   (392.0, 51.0),\n",
       "   (379.0, 38.0),\n",
       "   (374.0, 36.0),\n",
       "   (365.0, 29.0)],\n",
       "  'group_id': None,\n",
       "  'shape_type': 'polygon',\n",
       "  'flags': {}},\n",
       " {'label': 'car',\n",
       "  'points': [(418.0, 172.0),\n",
       "   (411.0, 176.0),\n",
       "   (409.0, 220.0),\n",
       "   (412.0, 225.0),\n",
       "   (417.0, 228.0),\n",
       "   (422.0, 230.0),\n",
       "   (428.0, 239.0),\n",
       "   (430.0, 251.0),\n",
       "   (449.0, 252.0),\n",
       "   (468.0, 251.0),\n",
       "   (485.0, 253.0),\n",
       "   (498.0, 173.0)],\n",
       "  'group_id': None,\n",
       "  'shape_type': 'polygon',\n",
       "  'flags': {}},\n",
       " {'label': 'truck',\n",
       "  'points': [(416.0, 170.0),\n",
       "   (411.0, 175.0),\n",
       "   (409.0, 222.0),\n",
       "   (414.0, 226.0),\n",
       "   (419.0, 229.0),\n",
       "   (426.0, 235.0),\n",
       "   (429.0, 242.0),\n",
       "   (443.0, 253.0),\n",
       "   (460.0, 252.0),\n",
       "   (469.0, 252.0),\n",
       "   (481.0, 253.0),\n",
       "   (498.0, 171.0)],\n",
       "  'group_id': None,\n",
       "  'shape_type': 'polygon',\n",
       "  'flags': {}}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imwrite('output.png',v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imantics import Polygons, Mask\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be any array\n",
    "array = mask[0]\n",
    "\n",
    "polygons = Mask(array).polygons()\n",
    "\n",
    "pol = cv2.polylines(im.copy(), [polygons.points[0][::2]], True, (0,255,0), 2)\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(pol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = model.inference('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(map(tuple, shape.astype('float')))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "former = [(152.53456221198158, 70.35483870967742), (108.7557603686636, 176.80645161290323), (270.5069124423963, 154.68663594470047)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(former[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/israel/test_env/bin/python3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# import imantics\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign()\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, threshold):\n",
    "    img = Image.open(img_path)\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img = transform(img)\n",
    "    pred = model([img])\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x>threshold][-1]\n",
    "    masks = (pred[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
    "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
    "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
    "    masks = masks[:pred_t+1]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return masks, pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/israel/test_env/lib/python3.8/site-packages/torchvision/ops/boxes.py:101: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  keep = keep.nonzero().squeeze(1)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/israel/repos/labelme/examples/test/2011_000025.jpg\"\n",
    "masks, pred_boxes, pred_class = get_prediction(path, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(masks[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from skimage import measure\n",
    "from PIL import Image\n",
    "from pycocotools import mask\n",
    "\n",
    "convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "natrual_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_binary_mask(array, new_size):\n",
    "    image = Image.fromarray(array.astype(np.uint8)*255)\n",
    "    image = image.resize(new_size)\n",
    "    return np.asarray(image).astype(np.bool_)\n",
    "\n",
    "def close_contour(contour):\n",
    "    if not np.array_equal(contour[0], contour[-1]):\n",
    "        contour = np.vstack((contour, contour[0]))\n",
    "    return contour\n",
    "\n",
    "def binary_mask_to_rle(binary_mask):\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order='F'))):\n",
    "        if i == 0 and value == 1:\n",
    "                counts.append(0)\n",
    "        counts.append(len(list(elements)))\n",
    "\n",
    "    return rle\n",
    "\n",
    "def binary_mask_to_polygon(binary_mask, tolerance=0):\n",
    "    \"\"\"Converts a binary mask to COCO polygon representation\n",
    "    Args:\n",
    "        binary_mask: a 2D binary numpy array where '1's represent the object\n",
    "        tolerance: Maximum distance from original points of polygon to approximated\n",
    "            polygonal chain. If tolerance is 0, the original coordinate array is returned.\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "    # pad mask to close contours of shapes which start and end at an edge\n",
    "    padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n",
    "    contours = measure.find_contours(padded_binary_mask, 0.5)\n",
    "    contours = np.subtract(contours, 1)\n",
    "    for contour in contours:\n",
    "        contour = close_contour(contour)\n",
    "        contour = measure.approximate_polygon(contour, tolerance)\n",
    "        if len(contour) < 3:\n",
    "            continue\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        seg = segmentation\n",
    "        # after padding and subtracting 1 we may get -0.5 points in our segmentation \n",
    "        segmentation = [0 if i < 0 else i for i in segmentation]\n",
    "        polygons.append(segmentation)\n",
    "\n",
    "    return polygons, seg, contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly, seg, con = binary_mask_to_polygon(masks[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
